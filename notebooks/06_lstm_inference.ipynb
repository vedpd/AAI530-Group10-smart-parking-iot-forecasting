{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: LSTM Model Inference - Smart Parking IoT System\n",
    "\n",
    "## Overview\n",
    "This notebook loads the best LSTM model and performs inference on the entire smart parking dataset.\n",
    "\n",
    "### Objectives\n",
    "- Load the best trained LSTM model\n",
    "- Perform inference on the complete dataset\n",
    "- Add predicted occupancy rate column\n",
    "- Identify train/test splits for each row\n",
    "- Analyze prediction quality and coverage\n",
    "\n",
    "### Model Information\n",
    "- Best LSTM Model: Loaded from Phase 5\n",
    "- Target: Occupancy Rate (0-1)\n",
    "- Input: 24-hour sequence of features\n",
    "- Output: 1-hour ahead prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the complete dataset\n",
    "print(\"ğŸ”„ Loading complete smart parking dataset...\")\n",
    "\n",
    "# Define data path\n",
    "data_path = Path(r\"C:\\Users\\vedp3\\OneDrive\\Desktop\\AAI_530_Final_Project\\AAI530-Group10-smart-parking-iot-forecasting\\data\\raw\\smart_parking_full.csv\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(data_path, sep=';')\n",
    "print(\"âœ… Complete dataset loaded successfully!\")\n",
    "print(f\"ğŸ“Š Dataset Shape: {df.shape}\")\n",
    "print(f\"   - Rows: {df.shape[0]:,}\")\n",
    "print(f\"   - Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best LSTM model and components\n",
    "print(\"ğŸ”„ Loading best LSTM model and components...\")\n",
    "\n",
    "# Define models directory\n",
    "models_dir = Path(r\"C:\\Users\\vedp3\\OneDrive\\Desktop\\AAI_530_Final_Project\\AAI530-Group10-smart-parking-iot-forecasting\\models\")\n",
    "\n",
    "# Load model metadata\n",
    "with open(models_dir / \"best_lstm_metadata.pkl\", 'rb') as f:\n",
    "    lstm_metadata = pickle.load(f)\n",
    "\n",
    "print(f\"ğŸ“‹ Model Metadata:\")\n",
    "print(f\"   Model Name: {lstm_metadata['model_name']}\")\n",
    "print(f\"   Model Type: {lstm_metadata['model_type']}\")\n",
    "print(f\"   Sequence Length: {lstm_metadata['sequence_length']}\")\n",
    "print(f\"   Forecast Horizon: {lstm_metadata['forecast_horizon']}\")\n",
    "print(f\"   Target Segment: {lstm_metadata['target_segment']}\")\n",
    "print(f\"   Performance RÂ²: {lstm_metadata['performance_metrics']['r2']:.4f}\")\n",
    "\n",
    "# Load the best LSTM model\n",
    "model_path = models_dir / f\"best_{lstm_metadata['model_name']}_model.h5\"\n",
    "best_model = load_model(model_path)\n",
    "print(f\"âœ… Best LSTM model loaded: {model_path.name}\")\n",
    "\n",
    "# Load scalers\n",
    "scaler_features = joblib.load(models_dir / \"lstm_feature_scaler.pkl\")\n",
    "scaler_target = joblib.load(models_dir / \"lstm_target_scaler.pkl\")\n",
    "print(\"âœ… Feature and target scalers loaded\")\n",
    "\n",
    "# Extract parameters\n",
    "SEQUENCE_LENGTH = lstm_metadata['sequence_length']\n",
    "FORECAST_HORIZON = lstm_metadata['forecast_horizon']\n",
    "features = lstm_metadata['features']\n",
    "target_segment = lstm_metadata['target_segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the complete dataset\n",
    "print(\"ğŸ”§ Preprocessing complete dataset for inference...\")\n",
    "\n",
    "# Convert timestamp and sort\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp')\n",
    "\n",
    "# Calculate occupancy rate\n",
    "df['occupancy_rate'] = df['occupied'] / df['capacity']\n",
    "df['occupancy_rate'] = df['occupancy_rate'].clip(0, 1)\n",
    "\n",
    "# Create time-based features\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "df['is_rush_hour'] = ((df['hour'].between(7, 9)) | (df['hour'].between(16, 18))).astype(int)\n",
    "\n",
    "# Create cyclical features\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Aggregate data by hour for consistency with training\n",
    "print(\"ğŸ“Š Aggregating data by hour...\")\n",
    "df_hourly = df.groupby([pd.Grouper(key='timestamp', freq='H'), 'segmentid']).agg({\n",
    "    'occupancy_rate': 'mean',\n",
    "    'capacity': 'mean',\n",
    "    'hour': 'first',\n",
    "    'day_of_week': 'first',\n",
    "    'month': 'first',\n",
    "    'is_weekend': 'first',\n",
    "    'is_rush_hour': 'first',\n",
    "    'hour_sin': 'first',\n",
    "    'hour_cos': 'first',\n",
    "    'day_sin': 'first',\n",
    "    'day_cos': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Filter for target segment\n",
    "df_target = df_hourly[df_hourly['segmentid'] == target_segment].copy()\n",
    "df_target = df_target.sort_values('timestamp')\n",
    "\n",
    "# Prepare features\n",
    "df_inference = df_target[features].copy()\n",
    "df_inference = df_inference.fillna(df_inference.median())\n",
    "\n",
    "print(f\"âœ… Dataset preprocessed for inference:\")\n",
    "print(f\"   Shape: {df_inference.shape}\")\n",
    "print(f\"   Time range: {df_target['timestamp'].min()} to {df_target['timestamp'].max()}\")\n",
    "print(f\"   Features: {features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for inference\n",
    "def create_inference_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM inference\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    \n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        sequences.append(data[i:(i + sequence_length)])\n",
    "    \n",
    "    return np.array(sequences)\n",
    "\n",
    "print(\"ğŸ”§ Creating sequences for inference...\")\n",
    "\n",
    "# Scale features\n",
    "features_scaled = scaler_features.transform(df_inference[features])\n",
    "\n",
    "# Create sequences\n",
    "X_inference = create_inference_sequences(features_scaled, SEQUENCE_LENGTH)\n",
    "\n",
    "print(f\"âœ… Inference sequences created:\")\n",
    "print(f\"   Input sequences shape: {X_inference.shape}\")\n",
    "print(f\"   Total predictions possible: {len(X_inference)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference on all sequences\n",
    "print(\"ğŸš€ Performing LSTM inference on all sequences...\")\n",
    "\n",
    "# Make predictions\n",
    "predictions_scaled = best_model.predict(X_inference, verbose=0)\n",
    "\n",
    "# Inverse transform predictions\n",
    "predictions = scaler_target.inverse_transform(predictions_scaled)\n",
    "\n",
    "print(f\"âœ… Inference completed:\")\n",
    "print(f\"   Predictions shape: {predictions.shape}\")\n",
    "print(f\"   Prediction range: {predictions.min():.4f} to {predictions.max():.4f}\")\n",
    "print(f\"   Mean prediction: {predictions.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final dataset with predictions and train/test labels\n",
    "print(\"ğŸ“Š Creating final dataset with predictions...\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = df_target.copy()\n",
    "\n",
    "# Add predictions (align with original data)\n",
    "# Predictions start from sequence_length index\n",
    "predictions_flat = predictions.flatten()\n",
    "prediction_indices = range(SEQUENCE_LENGTH, SEQUENCE_LENGTH + len(predictions_flat))\n",
    "\n",
    "# Initialize prediction column with NaN\n",
    "results_df['predicted_occupancy_rate'] = np.nan\n",
    "\n",
    "# Assign predictions to correct positions\n",
    "for i, idx in enumerate(prediction_indices):\n",
    "    if idx < len(results_df):\n",
    "        results_df.iloc[idx, results_df.columns.get_loc('predicted_occupancy_rate')] = predictions_flat[i]\n",
    "\n",
    "# Define train/test split (80/20 split like in training)\n",
    "split_point = int(len(results_df) * 0.8)\n",
    "\n",
    "# Add train/test labels\n",
    "results_df['data_split'] = 'train'\n",
    "results_df.iloc[split_point:, results_df.columns.get_loc('data_split')] = 'test'\n",
    "\n",
    "# Calculate prediction metrics where available\n",
    "valid_predictions = results_df.dropna(subset=['predicted_occupancy_rate'])\n",
    "\n",
    "if len(valid_predictions) > 0:\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    \n",
    "    mse = mean_squared_error(valid_predictions['occupancy_rate'], valid_predictions['predicted_occupancy_rate'])\n",
    "    mae = mean_absolute_error(valid_predictions['occupancy_rate'], valid_predictions['predicted_occupancy_rate'])\n",
    "    r2 = r2_score(valid_predictions['occupancy_rate'], valid_predictions['predicted_occupancy_rate'])\n",
    "    \n",
    "    print(f\"ğŸ“ˆ Prediction Quality Metrics:\")\n",
    "    print(f\"   MSE: {mse:.6f}\")\n",
    "    print(f\"   MAE: {mae:.6f}\")\n",
    "    print(f\"   RÂ²: {r2:.4f}\")\n",
    "    print(f\"   Valid predictions: {len(valid_predictions):,}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final Dataset Summary:\")\n",
    "print(f\"   Total rows: {len(results_df):,}\")\n",
    "print(f\"   Training rows: {len(results_df[results_df['data_split'] == 'train']):,}\")\n",
    "print(f\"   Testing rows: {len(results_df[results_df['data_split'] == 'test']):,}\")\n",
    "print(f\"   Rows with predictions: {len(valid_predictions):,}\")\n",
    "print(f\"   Rows without predictions: {len(results_df) - len(valid_predictions):,}\")\n",
    "\n",
    "# Display sample of results\n",
    "print(f\"\\nğŸ“‹ Sample Results:\")\n",
    "display_cols = ['timestamp', 'segmentid', 'occupancy_rate', 'predicted_occupancy_rate', 'data_split']\n",
    "display(results_df[display_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "print(\"ğŸ“ˆ Visualizing predictions...\")\n",
    "\n",
    "# Create visualization data\n",
    "viz_data = results_df.dropna(subset=['predicted_occupancy_rate']).copy()\n",
    "\n",
    "if len(viz_data) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    fig.suptitle('LSTM Model Predictions - Complete Dataset Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Time series comparison (sample)\n",
    "    sample_size = min(500, len(viz_data))\n",
    "    sample_data = viz_data.head(sample_size)\n",
    "    \n",
    "    axes[0,0].plot(sample_data['timestamp'], sample_data['occupancy_rate'], \n",
    "                    label='Actual', color='blue', linewidth=2, alpha=0.8)\n",
    "    axes[0,0].plot(sample_data['timestamp'], sample_data['predicted_occupancy_rate'], \n",
    "                    label='Predicted', color='red', linewidth=1.5, alpha=0.8)\n",
    "    axes[0,0].set_title('Predictions vs Actual (First 500 points)')\n",
    "    axes[0,0].set_xlabel('Time')\n",
    "    axes[0,0].set_ylabel('Occupancy Rate')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Scatter plot\n",
    "    axes[0,1].scatter(viz_data['occupancy_rate'], viz_data['predicted_occupancy_rate'], \n",
    "                      alpha=0.5, s=10)\n",
    "    min_val = min(viz_data['occupancy_rate'].min(), viz_data['predicted_occupancy_rate'].min())\n",
    "    max_val = max(viz_data['occupancy_rate'].max(), viz_data['predicted_occupancy_rate'].max())\n",
    "    axes[0,1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "    axes[0,1].set_title('Predictions vs Actual (Scatter)')\n",
    "    axes[0,1].set_xlabel('Actual Occupancy Rate')\n",
    "    axes[0,1].set_ylabel('Predicted Occupancy Rate')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Residuals\n",
    "    residuals = viz_data['occupancy_rate'] - viz_data['predicted_occupancy_rate']\n",
    "    axes[1,0].hist(residuals, bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[1,0].axvline(x=0, color='red', linestyle='--', alpha=0.8)\n",
    "    axes[1,0].set_title('Prediction Residuals Distribution')\n",
    "    axes[1,0].set_xlabel('Residuals')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Train/Test split visualization\n",
    "    train_data = results_df[results_df['data_split'] == 'train'].dropna(subset=['predicted_occupancy_rate'])\n",
    "    test_data = results_df[results_df['data_split'] == 'test'].dropna(subset=['predicted_occupancy_rate'])\n",
    "    \n",
    "    axes[1,1].scatter(train_data['occupancy_rate'], train_data['predicted_occupancy_rate'], \n",
    "                      alpha=0.5, s=8, color='blue', label='Train')\n",
    "    axes[1,1].scatter(test_data['occupancy_rate'], test_data['predicted_occupancy_rate'], \n",
    "                      alpha=0.5, s=8, color='red', label='Test')\n",
    "    \n",
    "    axes[1,1].plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8)\n",
    "    axes[1,1].set_title('Train vs Test Performance')\n",
    "    axes[1,1].set_xlabel('Actual Occupancy Rate')\n",
    "    axes[1,1].set_ylabel('Predicted Occupancy Rate')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âš ï¸ No valid predictions to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the complete inference results\n",
    "print(\"ğŸ’¾ Saving inference results...\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(r\"C:\\Users\\vedp3\\OneDrive\\Desktop\\AAI_530_Final_Project\\AAI530-Group10-smart-parking-iot-forecasting\\data\\inference\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save complete results\n",
    "output_path = output_dir / \"lstm_inference_complete_results.csv\"\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Save only rows with predictions\n",
    "predictions_only_path = output_dir / \"lstm_predictions_only.csv\"\n",
    "valid_predictions.to_csv(predictions_only_path, index=False)\n",
    "\n",
    "# Save inference metadata\n",
    "inference_metadata = {\n",
    "    'model_name': lstm_metadata['model_name'],\n",
    "    'model_type': 'LSTM',\n",
    "    'inference_timestamp': datetime.now().isoformat(),\n",
    "    'total_rows': len(results_df),\n",
    "    'train_rows': len(results_df[results_df['data_split'] == 'train']),\n",
    "    'test_rows': len(results_df[results_df['data_split'] == 'test']),\n",
    "    'prediction_rows': len(valid_predictions),\n",
    "    'sequence_length': SEQUENCE_LENGTH,\n",
    "    'target_segment': target_segment,\n",
    "    'performance_metrics': {\n",
    "        'mse': float(mse) if len(valid_predictions) > 0 else None,\n",
    "        'mae': float(mae) if len(valid_predictions) > 0 else None,\n",
    "        'r2': float(r2) if len(valid_predictions) > 0 else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_dir / \"inference_metadata.pkl\", 'wb') as f:\n",
    "    pickle.dump(inference_metadata, f)\n",
    "\n",
    "print(f\"âœ… Results saved successfully:\")\n",
    "print(f\"   Complete results: {output_path}\")\n",
    "print(f\"   Predictions only: {predictions_only_path}\")\n",
    "print(f\"   Metadata: {output_dir / 'inference_metadata.pkl'}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final Summary:\")\n",
    "print(f\"   ğŸ¯ Model: {lstm_metadata['model_name']}\")\n",
    "print(f\"   ğŸ“ˆ Total predictions: {len(valid_predictions):,}\")\n",
    "print(f\"   ğŸ·ï¸ Dataset split: {len(results_df[results_df['data_split'] == 'train']):,} train / {len(results_df[results_df['data_split'] == 'test']):,} test\")\n",
    "print(f\"   ğŸ“Š Prediction quality: RÂ² = {r2:.4f}\")\n",
    "print(f\"   ğŸ’¾ Output saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\nâœ… LSTM Inference Complete!\")\n",
    "print(f\"ğŸš€ Ready for production deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
